{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicle_speed_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3CT55LKIJrj"
      },
      "source": [
        "# **Approach:**\n",
        "\n",
        "# **Tasks breakdown:**\n",
        "\n",
        "  # **1.Vehicle Detection:**\n",
        "\n",
        "  1.1.We are using Haarcascade classifier to identify vehicles.\n",
        "\n",
        "  # **2.Vehicle Tracking - ( assigning IDs to vehicles )**\n",
        "\n",
        "  2.1 We have used correlation tracker from dlib library.\n",
        "\n",
        "  # **3.Speed Calculation:**\n",
        "\n",
        "  3.1.We are calculating the distance moved by the tracked vehicle in a second, in terms of pixels, so we need pixel per meter to calculate the distance travelled in meters.\n",
        "\n",
        "  3.2.With distance travelled per second in meters, we will get the speed of the vehicle.\n",
        "\n",
        "  I have used car pre-trained HaarCascade features xml file which returns coordinates of the the detected car and we can draw a bounding box using the coordinates. It is computationally less expensive with faster processing speed. The experiments on-road prove it to be a robust and real time algorithm which is highly competitive with the existing architecture.The model is very accurate and faster than algorithms like RCNN.\n",
        "\n",
        "  I have estimated these values manually for the current road to calculate pixels per metre(ppm). Therefore, the value will vary from road to road and have to be adjusted to be used on any other video.\n",
        "\n",
        "  If I talk about the part how we estimated ppm, we need to know the actual width in metres of the road(you can use google to find the approximate width of the road in your country). Also, we have taken the video frame and calculated the width of the road in pixels digitally. Now, we have the width of the road in metres from the real world and in pixels from our video frame. To map the distances between these two worlds, we have calculated pixels per metre by dividing distance of road in pixels to metres.\n",
        "\n",
        "  d_pixels gives the pixel distance travelled by the vehicle in one frame of our video processing. To estimate speed in any standard unit first, we need to convert d_pixels to d_metres.\n",
        "\n",
        "  Now, we can calculate the speed(speed = d_meters * fps * 3.6). d_meters is the distance travelled in one frame. We have already calculated the average fps during video processing. So, to get the speed in m/s, just (d_metres * fps) will do. We have multiplied that estimated speed with 3.6 to convert it into km/hr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyfdzWf6v4BO"
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import time\n",
        "import threading\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "carCascade = cv2.CascadeClassifier('myhaar.xml')\n",
        "video = cv2.VideoCapture('cars.mp4')\n",
        "\n",
        "WIDTH = 1280\n",
        "HEIGHT = 720\n",
        "\n",
        "\n",
        "def estimateSpeed(loc1, loc2):\n",
        "\td_pixels = math.sqrt(math.pow(loc2[0] - loc1[0], 2) + math.pow(loc2[1] - loc1[1], 2))\n",
        "\tppm = 8.8\n",
        "\td_meters = d_pixels / ppm\n",
        "\tfps = 18\n",
        "\tspeed = d_meters * fps * 3.6\n",
        "\treturn speed\n",
        "\t\n",
        "\n",
        "def Track_Multiple_Vehicles():\n",
        "\trectangleColor = (0, 255, 0)\n",
        "\tframeCounter = 0\n",
        "\tcurrentCarID = 0\n",
        "\tfps = 0\n",
        "\t\n",
        "\tcarTracker = {}\n",
        "\tcarNumbers = {}\n",
        "\tcarLocation1 = {}\n",
        "\tcarLocation2 = {}\n",
        "\tspeed = [None] * 1000\n",
        "\t\n",
        "\t# Write output to video file\n",
        "\tout = cv2.VideoWriter('speed_output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (WIDTH,HEIGHT))\n",
        "\n",
        "\n",
        "\twhile True:\n",
        "\t\tstart_time = time.time()\n",
        "\t\trc, image = video.read()\n",
        "\t\tif type(image) == type(None):\n",
        "\t\t\tbreak\n",
        "\t\t\n",
        "\t\timage = cv2.resize(image, (WIDTH, HEIGHT))\n",
        "\t\tresultImage = image.copy()\n",
        "\t\t\n",
        "\t\tframeCounter = frameCounter + 1\n",
        "\t\t\n",
        "\t\tcarIDtoDelete = []\n",
        "\n",
        "\t\tfor carID in carTracker.keys():\n",
        "\t\t\ttrackingQuality = carTracker[carID].update(image)\n",
        "\t\t\t\n",
        "\t\t\tif trackingQuality < 7:\n",
        "\t\t\t\tcarIDtoDelete.append(carID)\n",
        "\t\t\t\t\n",
        "\t\tfor carID in carIDtoDelete:\n",
        "\t\t\tprint ('Removing carID ' + str(carID) + ' from list of trackers.')\n",
        "\t\t\tprint ('Removing carID ' + str(carID) + ' previous location.')\n",
        "\t\t\tprint ('Removing carID ' + str(carID) + ' current location.')\n",
        "\t\t\tcarTracker.pop(carID, None)\n",
        "\t\t\tcarLocation1.pop(carID, None)\n",
        "\t\t\tcarLocation2.pop(carID, None)\n",
        "\t\t\n",
        "\t\tif not (frameCounter % 10):\n",
        "\t\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\tcars = carCascade.detectMultiScale(gray, 1.1, 13, 18, (24, 24))\n",
        "\t\t\t\n",
        "\t\t\tfor (_x, _y, _w, _h) in cars:\n",
        "\t\t\t\tx = int(_x)\n",
        "\t\t\t\ty = int(_y)\n",
        "\t\t\t\tw = int(_w)\n",
        "\t\t\t\th = int(_h)\n",
        "\t\t\t\n",
        "\t\t\t\tx_bar = x + 0.5 * w\n",
        "\t\t\t\ty_bar = y + 0.5 * h\n",
        "\t\t\t\t\n",
        "\t\t\t\tmatchCarID = None\n",
        "\t\t\t\n",
        "\t\t\t\tfor carID in carTracker.keys():\n",
        "\t\t\t\t\ttrackedPosition = carTracker[carID].get_position()\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tt_x = int(trackedPosition.left())\n",
        "\t\t\t\t\tt_y = int(trackedPosition.top())\n",
        "\t\t\t\t\tt_w = int(trackedPosition.width())\n",
        "\t\t\t\t\tt_h = int(trackedPosition.height())\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tt_x_bar = t_x + 0.5 * t_w\n",
        "\t\t\t\t\tt_y_bar = t_y + 0.5 * t_h\n",
        "\t\t\t\t\n",
        "\t\t\t\t\tif ((t_x <= x_bar <= (t_x + t_w)) and (t_y <= y_bar <= (t_y + t_h)) and (x <= t_x_bar <= (x + w)) and (y <= t_y_bar <= (y + h))):\n",
        "\t\t\t\t\t\tmatchCarID = carID\n",
        "\t\t\t\t\n",
        "\t\t\t\tif matchCarID is None:\n",
        "\t\t\t\t\tprint ('Creating new tracker ' + str(currentCarID))\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\ttracker = dlib.correlation_tracker()\n",
        "\t\t\t\t\ttracker.start_track(image, dlib.rectangle(x, y, x + w, y + h))\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tcarTracker[currentCarID] = tracker\n",
        "\t\t\t\t\tcarLocation1[currentCarID] = [x, y, w, h]\n",
        "\n",
        "\t\t\t\t\tcurrentCarID = currentCarID + 1\n",
        "\n",
        "\n",
        "\n",
        "\t\tfor carID in carTracker.keys():\n",
        "\t\t\ttrackedPosition = carTracker[carID].get_position()\n",
        "\t\t\t\t\t\n",
        "\t\t\tt_x = int(trackedPosition.left())\n",
        "\t\t\tt_y = int(trackedPosition.top())\n",
        "\t\t\tt_w = int(trackedPosition.width())\n",
        "\t\t\tt_h = int(trackedPosition.height())\n",
        "\t\t\t\n",
        "\t\t\tcv2.rectangle(resultImage, (t_x, t_y), (t_x + t_w, t_y + t_h), rectangleColor, 4)\n",
        "\t\t\t\n",
        "\t\t\t# speed estimation\n",
        "\t\t\tcarLocation2[carID] = [t_x, t_y, t_w, t_h]\n",
        "\t\t\n",
        "\t\tend_time = time.time()\n",
        "\t\t\n",
        "\t\tif not (end_time == start_time):\n",
        "\t\t\tfps = 1.0/(end_time - start_time)\n",
        "\n",
        "\n",
        "\t\tfor i in carLocation1.keys():\t\n",
        "\t\t\tif frameCounter % 1 == 0:\n",
        "\t\t\t\t[x1, y1, w1, h1] = carLocation1[i]\n",
        "\t\t\t\t[x2, y2, w2, h2] = carLocation2[i]\n",
        "\t\t\t\tcarLocation1[i] = [x2, y2, w2, h2]\n",
        "\t\t\t\tif [x1, y1, w1, h1] != [x2, y2, w2, h2]:\n",
        "\t\t\t\t\tif (speed[i] == None or speed[i] == 0) and y1 >= 275 and y1 <= 285:\n",
        "\t\t\t\t\t\tspeed[i] = estimateSpeed([x1, y1, w1, h1], [x2, y2, w2, h2])\n",
        "\n",
        "\t\t\t\t\tif speed[i] != None and y1 >= 180:\n",
        "\t\t\t\t\t\tcv2.putText(resultImage, str(int(speed[i])) + \" km/hr\", (int(x1 + w1/2), int(y1-5)),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\n",
        "\t\tcv2.imshow(resultImage)\n",
        "\t\t# Write the frame into the file 'output.avi'\n",
        "\t\tout.write(resultImage)\n",
        "\n",
        "\n",
        "\t\tif cv2.waitKey(33) == 27:\n",
        "\t\t\tbreak\n",
        "\t\n",
        "\tcv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tTrack_Multiple_Vehicles()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}